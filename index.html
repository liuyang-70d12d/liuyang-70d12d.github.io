<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1"><meta name="format-detection" content="telephone=no"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black"><link rel="icon" href="/assets/favicon/favicon_01/favicon-16x16.png?v=2.3.0" type="image/png" sizes="16x16"><link rel="icon" href="/assets/favicon/favicon_01/favicon-32x32.png?v=2.3.0" type="image/png" sizes="32x32"><meta property="og:type" content="website">
<meta property="og:title" content="Hello, Stranger">
<meta property="og:url" content="https://hello-liuyang.com/index.html">
<meta property="og:site_name" content="Hello, Stranger">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="liuyang-70d12d">
<meta name="twitter:card" content="summary"><title>Hello, Stranger</title><link ref="canonical" href="https://hello-liuyang.com/index.html"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.12.1/css/all.min.css" type="text/css"><link rel="stylesheet" href="/css/index.css?v=2.3.0"><script>var Stun = window.Stun || {};
var CONFIG = {
  root: '/',
  algolia: undefined,
  assistSearch: undefined,
  fontIcon: {"prompt":{"success":"fas fa-check-circle","info":"fas fa-arrow-circle-right","warning":"fas fa-exclamation-circle","error":"fas fa-times-circle"},"copyBtn":"fas fa-copy"},
  sidebar: {"offsetTop":"20px","tocMaxDepth":6},
  header: {"enable":true,"showOnPost":false,"scrollDownIcon":true},
  postWidget: {"endText":true},
  nightMode: {"enable":true},
  back2top: {"enable":true},
  codeblock: {"style":"default","highlight":"light","wordWrap":false},
  reward: false,
  fancybox: false,
  zoomImage: {"gapAside":"20px"},
  galleryWaterfall: undefined,
  lazyload: false,
  pjax: undefined,
  externalLink: {"icon":{"enable":true,"name":"fas fa-external-link-alt"}},
  shortcuts: undefined,
  prompt: {"copyButton":"Copy","copySuccess":"Copy Success","copyError":"Copy Error"},
  sourcePath: {"js":"js","css":"css","images":"images"},
};

window.CONFIG = CONFIG;</script><meta name="generator" content="Hexo 5.2.0"></head><body><div class="container" id="container"><header class="header" id="header"><div class="header-inner"><nav class="header-nav header-nav--fixed"><div class="header-nav-inner"><div class="header-nav-menubtn"><i class="fas fa-bars"></i></div><div class="header-nav-menu"><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/"><span class="header-nav-menu-item__icon"><i class="fas fa-home"></i></span><span class="header-nav-menu-item__text">Home</span></a></div><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/archives/"><span class="header-nav-menu-item__icon"><i class="fas fa-folder-open"></i></span><span class="header-nav-menu-item__text">Archives</span></a></div><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/tags/"><span class="header-nav-menu-item__icon"><i class="fas fa-tags"></i></span><span class="header-nav-menu-item__text">Tags</span></a></div></div><div class="header-nav-mode"><div class="mode"><div class="mode-track"><span class="mode-track-moon"></span><span class="mode-track-sun"></span></div><div class="mode-thumb"></div></div></div></div></nav><div class="header-banner"><div class="header-banner-info"><div class="header-banner-info__title">Hello, Stranger</div><div class="header-banner-info__subtitle"></div></div><div class="header-banner-arrow"><div class="header-banner-arrow__icon"><i class="fas fa-angle-down"></i></div></div></div></div></header><main class="main" id="main"><div class="main-inner"><div class="content-wrap" id="content-wrap"><div class="content content-home" id="content"><section class="postlist"><article class="postlist-item post"><header class="post-header"><h1 class="post-title"><a class="post-title__link" href="/2021/01/07/Ubuntu-16-04-%E5%AE%89%E8%A3%85-Hyperledger-Fabric1-4/">Ubuntu 16.04 安装 Hyperledger Fabric1.4</a></h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">Created</span><span class="post-meta-item__value">2021-01-07</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">Updated</span><span class="post-meta-item__value">2021-01-07</span></span></div></header><div class="post-body"><div class="post-excerpt"><h3 id="安装环境">
          <a href="#安装环境" class="heading-link"><i class="fas fa-link"></i></a>安装环境</h3>
      
<p>阿里云 轻量应用服务器 Ubuntu 16.04.6</p>

        <h3 id="注意">
          <a href="#注意" class="heading-link"><i class="fas fa-link"></i></a>注意</h3>
      
<p>Hyperledger Fabric 依赖的软件版本查看 <span class="exturl"><a class="exturl__link" target="_blank" rel="noopener" href="https://github.com/hyperledger/fabric">官方 github 地址</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span> 下文件 <code>/docs/source/prereqs.rst</code>，软件版本要求根据安装的 Fabric 的版本差异而略有不同。</p></div><div class="post-readmore"><a class="post-readmore__link" href="/2021/01/07/Ubuntu-16-04-%E5%AE%89%E8%A3%85-Hyperledger-Fabric1-4/"><span class="post-readmore__text">Read More</span><span class="post-readmore__icon"><i class="fas fa-long-arrow-alt-right"></i></span></a></div></div></article><article class="postlist-item post"><header class="post-header"><h1 class="post-title"><a class="post-title__link" href="/2021/01/05/%E6%95%B0%E6%8D%AE%EF%BC%9A%E5%B7%A5%E4%B8%9A%E4%BA%92%E8%81%94%E7%BD%91/">数据：工业互联网</a></h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">Created</span><span class="post-meta-item__value">2021-01-05</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">Updated</span><span class="post-meta-item__value">2021-01-07</span></span></div></header><div class="post-body"><div class="post-excerpt">
        <h2 id="网站">
          <a href="#网站" class="heading-link"><i class="fas fa-link"></i></a>网站</h2>
      
<p><span class="exturl"><a class="exturl__link" target="_blank" rel="noopener" href="http://www.aii-alliance.org/bps/">工业互联网产业联盟-白皮书</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></p>

        <h2 id="白皮书">
          <a href="#白皮书" class="heading-link"><i class="fas fa-link"></i></a>白皮书</h2>
      
<p><span class="exturl"><a class="exturl__link" target="_blank" rel="noopener" href="https://www.china-aii.com/ueditor/php/upload/file/20200819/1597805791104976.pdf">中国工业互联网产业经济发展白皮书（2020年）- 中国工业互联网研究院</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></p>
<p><span class="exturl"><a class="exturl__link" target="_blank" rel="noopener" href="http://www.aii-alliance.org/static/upload/202009/0907_101809_849.pdf">工业PON 2.0 白皮书 - 中国工业互联网产业联盟</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></p>
<p><span class="exturl"><a class="exturl__link" target="_blank" rel="noopener" href="http://www.aii-alliance.org/static/upload/202009/0901_165010_961.pdf">工业互联网时间敏感网络（TSN）产业白皮书 - 中国工业互联网产业联盟</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></p>
<p><span class="exturl"><a class="exturl__link" target="_blank" rel="noopener" href="http://www.aii-alliance.org/bps/20200430/2063.html">工业互联网体系架构（版本 2.0）- 中国工业互联网产业联盟</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></p>
<p><span class="exturl"><a class="exturl__link" target="_blank" rel="noopener" href="http://www.cnic.cas.cn/xwdt/yfdt/201811/P020181108393346075254.pdf">边缘计算技术研究报告 - 中国科学院计算机网络信息中心</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></p>
<p><span class="exturl"><a class="exturl__link" target="_blank" rel="noopener" href="http://www.aii-alliance.org/bps/20200302/843.html">工业互联网网络连接白皮书 - 中国工业互联网产业联盟</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></p>
</div></div></article><article class="postlist-item post"><header class="post-header"><h1 class="post-title"><a class="post-title__link" href="/2020/12/31/Paper-Note-PathNet-Evolution-Channels-Gradient-Descent-in-Super-Neural-Networks/">Paper Note: PathNet: Evolution Channels Gradient Descent in Super Neural Networks</a></h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">Created</span><span class="post-meta-item__value">2020-12-31</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">Updated</span><span class="post-meta-item__value">2021-01-01</span></span></div></header><div class="post-body"><div class="post-excerpt"><p><font face="Adobe Caslon Pro"><strong>PathNet: Evolution Channels Gradient Descent in Super Neural<br>
Networks</strong></font></p>
<p><font face="Adobe Caslon Pro"><em>Chrisantha Fernando, Dylan Banarse, Charles Blundell, Yori Zwols, David Ha, Andrei A. Rusu, Alexander Pritzel, Daan Wierstra</em></font></p>
<p><font face="Adobe Caslon Pro"><em>arXiv:1701.08734</em> </font></p>
<p><font face="Adobe Caslon Pro">[<span class="exturl"><a class="exturl__link" target="_blank" rel="noopener" href="https://arxiv.org/abs/1701.08734">paper</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>]</font> <font face="Adobe Caslon Pro">[<span class="exturl"><a class="exturl__link" target="_blank" rel="noopener" href="https://github.com/jsikyoon/pathnet">code_1</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>]</font> <font face="Adobe Caslon Pro">[<span class="exturl"><a class="exturl__link" target="_blank" rel="noopener" href="https://github.com/kimhc6028/pathnet-pytorch">code_2</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>]</font></p></div><div class="post-readmore"><a class="post-readmore__link" href="/2020/12/31/Paper-Note-PathNet-Evolution-Channels-Gradient-Descent-in-Super-Neural-Networks/"><span class="post-readmore__text">Read More</span><span class="post-readmore__icon"><i class="fas fa-long-arrow-alt-right"></i></span></a></div></div></article><article class="postlist-item post"><header class="post-header"><h1 class="post-title"><a class="post-title__link" href="/2020/12/30/Paper-Note-Overcoming-Catastrophic-Forgetting-with-Hard-Attention-to-the-Task/">Paper Note: Overcoming Catastrophic Forgetting with Hard Attention to the Task</a></h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">Created</span><span class="post-meta-item__value">2020-12-30</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">Updated</span><span class="post-meta-item__value">2020-12-31</span></span></div></header><div class="post-body"><div class="post-excerpt"><p><font face="Adobe Caslon Pro"><strong>Overcoming Catastrophic Forgetting with Hard Attention to the Task</strong></font></p>
<p><font face="Adobe Caslon Pro"><em>Joan Serra, Didac Suris, Marius Miron, Alexandros Karatzoglou</em></font></p>
<p><font face="Adobe Caslon Pro"><em>ICML 2018</em> </font></p>
<p><font face="Adobe Caslon Pro">[<span class="exturl"><a class="exturl__link" target="_blank" rel="noopener" href="http://proceedings.mlr.press/v80/serra18a.html">paper</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>]</font> <font face="Adobe Caslon Pro">[<span class="exturl"><a class="exturl__link" target="_blank" rel="noopener" href="https://github.com/joansj/hat">code</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>]</font></p>

        <h2 id="font-faceadobe-caslon-prorelated-workfont">
          <a href="#font-faceadobe-caslon-prorelated-workfont" class="heading-link"><i class="fas fa-link"></i></a>Related Work</h2>
      
<p><font face="Adobe Caslon Pro">文章评价了一下 rehearsal（<em>Rebuffi et al., 2017; Lopez-Paz &amp; Ranzato, 2017</em>）和 pseudo-rehearsal（<em>Venkatesan et al., 2017; Shin et al., 2017; Nguyen et al., 2017</em>）的方法：rehearsal 的方法对存储资源有要求；pseudo-rehearsal 的方法一般是使用生成网络（generative network），而为一系列任务的数据训练生成网络其实并不容易。而且这两种方法都意味着某种形式上的 concurrent learning，也就是说需要在学习新的任务时去对“旧”的数据再进行处理。</font></p>

        <h2 id="font-faceadobe-caslon-promain-ideafont">
          <a href="#font-faceadobe-caslon-promain-ideafont" class="heading-link"><i class="fas fa-link"></i></a>Main Idea</h2>
      
<p><font face="Adobe Caslon Pro">本文提出了一种基于任务的硬注意力机制（hard attention mechanism），该机制可维护先前任务中的信息，而不会影响新任务的学习。在学习一项任务的同时，我们还通过 gated task embeddings 来学习 almost-binary attention vectors。先前任务的注意力向量用于定义 mask，以此限制在当前任务上更新网络的某些权重。由于 mask 几乎是二值的，因此一部分权重会保持不变，而其余部分则会去适应新的任务。我们称我们的方法为 hard attention to the task (HAT)。</font></p>

        <h3 id="font-faceadobe-caslon-promotivationfont">
          <a href="#font-faceadobe-caslon-promotivationfont" class="heading-link"><i class="fas fa-link"></i></a>Motivation</h3>
      
<p><font face="Adobe Caslon Pro">提出HAT想法的出发点在于：任务定义（task definition），或更实际地说，任务的标识符（task identifier）对于神经网络的运行至关重要。考虑在训练区分鸟和狗图像的任务时，网络可能会学习到一些中间特征。如果第二项任务是使用相同的数据来区分棕色和黑色动物（假设数据只包含棕色或黑色的鸟和狗），则网络可能会学习到一组新的特征，而这些特征与第一组特征可能几乎没有太多交集。因此，如果两个任务中的训练数据相同，则一个重要的区别就是它们的任务描述或标识符。我们的目的是学习使用任务标识符来对每一层神经网络进行条件限制，并在以后使用这种学习到的条件限制来防止忘记先前的任务。</font></p>

        <h3 id="font-faceadobe-caslon-proarchitecturefont">
          <a href="#font-faceadobe-caslon-proarchitecturefont" class="heading-link"><i class="fas fa-link"></i></a>Architecture</h3>
      
<p><font face="Adobe Caslon Pro">为了对任务 t 施加条件限制，我们使用一种 layer-wise 的注意力机制（如 Fig. 1 所示）。当给出 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>l</mi></mrow><annotation encoding="application/x-tex">l</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span></span></span></span> 层 units （在本文中，units 既指 linear units（即全连接层的神经元），又指卷积层的 filters）的输出 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi mathvariant="bold-italic">h</mi><mi>l</mi></msub></mrow><annotation encoding="application/x-tex">\boldsymbol{h}_l</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord"><span class="mord"><span class="mord boldsymbol">h</span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> ，我们对其施以 element-wise 的乘法 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msubsup><mi mathvariant="bold-italic">h</mi><mi>l</mi><mo mathvariant="normal">′</mo></msubsup><mo>=</mo><msubsup><mi mathvariant="bold-italic">a</mi><mi>l</mi><mi>t</mi></msubsup><mo>⊙</mo><msub><mi mathvariant="bold-italic">h</mi><mi>l</mi></msub></mrow><annotation encoding="application/x-tex">\boldsymbol{h}&#x27;_l=\boldsymbol{a}_l^t\odot\boldsymbol{h}_l</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.083232em;vertical-align:-0.247em;"></span><span class="mord"><span class="mord"><span class="mord"><span class="mord boldsymbol">h</span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.836232em;"><span style="top:-2.4530000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span></span></span><span style="top:-3.1473400000000002em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.0766639999999998em;vertical-align:-0.2831079999999999em;"></span><span class="mord"><span class="mord"><span class="mord"><span class="mord boldsymbol">a</span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7935559999999999em;"><span style="top:-2.4168920000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2831079999999999em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⊙</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord"><span class="mord"><span class="mord boldsymbol">h</span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 。<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msubsup><mi mathvariant="bold-italic">a</mi><mi>l</mi><mi>t</mi></msubsup></mrow><annotation encoding="application/x-tex">\boldsymbol{a}_l^t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0766639999999998em;vertical-align:-0.2831079999999999em;"></span><span class="mord"><span class="mord"><span class="mord"><span class="mord boldsymbol">a</span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7935559999999999em;"><span style="top:-2.4168920000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2831079999999999em;"><span></span></span></span></span></span></span></span></span></span> 是一个单层的 task embedding <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msubsup><mi mathvariant="bold-italic">e</mi><mi>l</mi><mi>t</mi></msubsup></mrow><annotation encoding="application/x-tex">\boldsymbol{e}_l^t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0766639999999998em;vertical-align:-0.2831079999999999em;"></span><span class="mord"><span class="mord"><span class="mord"><span class="mord boldsymbol">e</span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7935559999999999em;"><span style="top:-2.4168920000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2831079999999999em;"><span></span></span></span></span></span></span></span></span></span> 的 gated version：</font></p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msubsup><mi mathvariant="bold-italic">a</mi><mi>l</mi><mi>t</mi></msubsup><mo>=</mo><mi>σ</mi><mo stretchy="false">(</mo><mi>s</mi><msubsup><mi mathvariant="bold-italic">e</mi><mi>l</mi><mi>t</mi></msubsup><mo stretchy="false">)</mo><mspace width="2em"><mspace width="2em"><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mspace></mspace></mrow><annotation encoding="application/x-tex">\boldsymbol{a}_l^t=\sigma(s\boldsymbol{e}_l^t)\qquad\qquad(1)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0905559999999999em;vertical-align:-0.247em;"></span><span class="mord"><span class="mord"><span class="mord"><span class="mord boldsymbol">a</span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8435559999999999em;"><span style="top:-2.4530000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.093556em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">σ</span><span class="mopen">(</span><span class="mord mathdefault">s</span><span class="mord"><span class="mord"><span class="mord"><span class="mord boldsymbol">e</span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8435559999999999em;"><span style="top:-2.4530000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:2em;"></span><span class="mspace" style="margin-right:2em;"></span><span class="mopen">(</span><span class="mord">1</span><span class="mclose">)</span></span></span></span></span></p>
<p><font face="Adobe Caslon Pro">其中 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>σ</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>∈</mo><mo stretchy="false">[</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">\sigma(x)\in[0,1]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">σ</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">1</span><span class="mclose">]</span></span></span></span> 是一个门函数，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>s</mi></mrow><annotation encoding="application/x-tex">s</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">s</span></span></span></span> 是一个正的的调幅参数。Eq. 1 对 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>l</mi><mo>=</mo><mn>1</mn><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><mi>L</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">l=1,...,L-1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">L</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span> 的所有层都适用。而对于 L 层，也就是网络的最后一层，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msubsup><mi mathvariant="bold-italic">a</mi><mi>L</mi><mi>t</mi></msubsup></mrow><annotation encoding="application/x-tex">\boldsymbol{a}_L^t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.068887em;vertical-align:-0.275331em;"></span><span class="mord"><span class="mord"><span class="mord"><span class="mord boldsymbol">a</span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7935559999999999em;"><span style="top:-2.424669em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">L</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.275331em;"><span></span></span></span></span></span></span></span></span></span> 是二值硬编码的。</font></p>
<img src="/2020/12/30/Paper-Note-Overcoming-Catastrophic-Forgetting-with-Hard-Attention-to-the-Task/01.png" class>
<p><font face="Adobe Caslon Pro">Figure 1. 示意图：上半部分是前向传播，下半部分是后向传播</font></p>
<p><font face="Adobe Caslon Pro">Eq. 1所表示的门机制是想要形成 hard, possibly binary attention masks，以此激活或者抑活每一层units的输出。</font></p>
<p><font face="Adobe Caslon Pro"></font></p>
<p><font face="Adobe Caslon Pro"></font></p>
<p><font face="Adobe Caslon Pro"></font></p>
</div></div></article><article class="postlist-item post"><header class="post-header"><h1 class="post-title"><a class="post-title__link" href="/2020/12/30/Paper-Note-Continual-Learning-of-a-Mixed-Sequence-of-Similar-and-Dissimilar-Tasks/">Paper Note: Continual Learning of a Mixed Sequence of Similar and Dissimilar Tasks</a></h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">Created</span><span class="post-meta-item__value">2020-12-30</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">Updated</span><span class="post-meta-item__value">2020-12-30</span></span></div></header><div class="post-body"><div class="post-excerpt"><p><font face="Adobe Caslon Pro"><strong>Continual Learning of a Mixed Sequence of Similar and Dissimilar Tasks</strong></font></p>
<p><font face="Adobe Caslon Pro"><em>Zixuan Ke, Bing Liu, Xingchang Huang</em></font></p>
<p><font face="Adobe Caslon Pro"><em>NeurlIPS 2020</em> </font></p>
<p><font face="Adobe Caslon Pro">[<span class="exturl"><a class="exturl__link" target="_blank" rel="noopener" href="https://papers.nips.cc/paper/2020/hash/d7488039246a405baf6a7cbc3613a56f-Abstract.html">paper</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>]</font> <font face="Adobe Caslon Pro">[<span class="exturl"><a class="exturl__link" target="_blank" rel="noopener" href="https://github.com/ZixuanKe/CAT">code</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>]</font></p></div><div class="post-readmore"><a class="post-readmore__link" href="/2020/12/30/Paper-Note-Continual-Learning-of-a-Mixed-Sequence-of-Similar-and-Dissimilar-Tasks/"><span class="post-readmore__text">Read More</span><span class="post-readmore__icon"><i class="fas fa-long-arrow-alt-right"></i></span></a></div></div></article><article class="postlist-item post"><header class="post-header"><h1 class="post-title"><a class="post-title__link" href="/2020/12/29/Paper-Note-Continual-Learning-with-Node-Importance-based-Adaptive-Group-Sparse-Regularization/">Paper Note: Continual Learning with Node-Importance based Adaptive Group Sparse Regularization</a></h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">Created</span><span class="post-meta-item__value">2020-12-29</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">Updated</span><span class="post-meta-item__value">2021-01-01</span></span></div></header><div class="post-body"><div class="post-excerpt"><p><font face="Adobe Caslon Pro"><strong>Continual Learning with Node-Importance based Adaptive Group Sparse Regularization</strong></font></p>
<p><font face="Adobe Caslon Pro"><em>Sangwon Jung, Hongjoon Ahn, Sungmin Cha, Taesup Moon</em></font></p>
<p><font face="Adobe Caslon Pro"><em>NeurlIPS 2020</em> </font></p>
<p><font face="Adobe Caslon Pro">[<span class="exturl"><a class="exturl__link" target="_blank" rel="noopener" href="https://papers.nips.cc/paper/2020/hash/258be18e31c8188555c2ff05b4d542c3-Abstract.html">paper</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>]</font></p></div><div class="post-readmore"><a class="post-readmore__link" href="/2020/12/29/Paper-Note-Continual-Learning-with-Node-Importance-based-Adaptive-Group-Sparse-Regularization/"><span class="post-readmore__text">Read More</span><span class="post-readmore__icon"><i class="fas fa-long-arrow-alt-right"></i></span></a></div></div></article><article class="postlist-item post"><header class="post-header"><h1 class="post-title"><a class="post-title__link" href="/2020/12/28/AWS-EC2-Ubuntu-18-04-%E5%AE%89%E8%A3%85-K8s/">AWS EC2 Ubuntu 18.04 安装 K8s</a></h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">Created</span><span class="post-meta-item__value">2020-12-28</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">Updated</span><span class="post-meta-item__value">2020-12-30</span></span></div></header><div class="post-body"><div class="post-excerpt"><p><strong>参考资料：</strong></p>
<ol>
<li><span class="exturl"><a class="exturl__link" target="_blank" rel="noopener" href="https://blog.csdn.net/wangkaizheng123/article/details/107491114">史上最全的k8s在ubuntu18.04上的安装</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></li>
<li><span class="exturl"><a class="exturl__link" target="_blank" rel="noopener" href="https://blog.csdn.net/April_er/article/details/108505476?utm_medium=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param&amp;depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param">ubuntu18.04 K8s集群超简单成功搭建！！笔记</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></li>
<li><span class="exturl"><a class="exturl__link" target="_blank" rel="noopener" href="https://www.cnblogs.com/mkxfs/p/12915659.html">ubuntu18.04.4安装k8s</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></li>
</ol></div><div class="post-readmore"><a class="post-readmore__link" href="/2020/12/28/AWS-EC2-Ubuntu-18-04-%E5%AE%89%E8%A3%85-K8s/"><span class="post-readmore__text">Read More</span><span class="post-readmore__icon"><i class="fas fa-long-arrow-alt-right"></i></span></a></div></div></article><article class="postlist-item post"><header class="post-header"><h1 class="post-title"><a class="post-title__link" href="/2020/12/24/Paper-Note-Scalable-and-Order-robust-Continual-Learning-with-Additive-Parameter-Decomposition/">Paper Note: Scalable and Order-robust Continual Learning with Additive Parameter Decomposition</a></h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">Created</span><span class="post-meta-item__value">2020-12-24</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">Updated</span><span class="post-meta-item__value">2020-12-28</span></span></div></header><div class="post-body"><div class="post-excerpt"><p><font face="Adobe Caslon Pro"><strong>Scalable and Order-robust Continual Learning with Additive Parameter Decomposition</strong></font></p>
<p><font face="Adobe Caslon Pro"><em>Jaehong Yoon, Saehoon Kim, Eunho Yang, Sung Ju Hwang</em></font></p>
<p><font face="Adobe Caslon Pro"><em>ICLR 2020</em> </font></p>
<p><font face="Adobe Caslon Pro">[<span class="exturl"><a class="exturl__link" target="_blank" rel="noopener" href="https://openreview.net/forum?id=r1gdj2EKPB">paper</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>]</font> <font face="Adobe Caslon Pro">[<span class="exturl"><a class="exturl__link" target="_blank" rel="noopener" href="https://github.com/iclr2020-apd/anonymous_iclr2020_apd_code">code</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>]</font></p></div><div class="post-readmore"><a class="post-readmore__link" href="/2020/12/24/Paper-Note-Scalable-and-Order-robust-Continual-Learning-with-Additive-Parameter-Decomposition/"><span class="post-readmore__text">Read More</span><span class="post-readmore__icon"><i class="fas fa-long-arrow-alt-right"></i></span></a></div></div></article><article class="postlist-item post"><header class="post-header"><h1 class="post-title"><a class="post-title__link" href="/2020/12/23/Paper-Note-Reinforced-Continual-Learning/">Paper Note: Reinforced Continual Learning</a></h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">Created</span><span class="post-meta-item__value">2020-12-23</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">Updated</span><span class="post-meta-item__value">2020-12-30</span></span></div></header><div class="post-body"><div class="post-excerpt"><p><font face="Adobe Caslon Pro"><strong>Reinforced Continual Learning</strong></font></p>
<p><font face="Adobe Caslon Pro"><em>Ju Xu, Zhanxing Zhu</em></font></p>
<p><font face="Adobe Caslon Pro"><em>NeurlIPS 2018</em> </font></p>
<p><font face="Adobe Caslon Pro">[<span class="exturl"><a class="exturl__link" target="_blank" rel="noopener" href="https://papers.nips.cc/paper/2018/hash/cee631121c2ec9232f3a2f028ad5c89b-Abstract.html">paper</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>]</font> <font face="Adobe Caslon Pro">[<span class="exturl"><a class="exturl__link" target="_blank" rel="noopener" href="https://github.com/xujinfan/Reinforced-Continual-Learning">code</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>]</font></p></div><div class="post-readmore"><a class="post-readmore__link" href="/2020/12/23/Paper-Note-Reinforced-Continual-Learning/"><span class="post-readmore__text">Read More</span><span class="post-readmore__icon"><i class="fas fa-long-arrow-alt-right"></i></span></a></div></div></article><article class="postlist-item post"><header class="post-header"><h1 class="post-title"><a class="post-title__link" href="/2020/12/23/Paper-Note-Learn-to-Grow-A-Continual-Structure-Learning-Framework-for-Overcoming-Catastrophic-Forgetting/">Paper Note: Learn to Grow: A Continual Structure Learning Framework for Overcoming Catastrophic Forgetting</a></h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">Created</span><span class="post-meta-item__value">2020-12-23</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">Updated</span><span class="post-meta-item__value">2020-12-23</span></span></div></header><div class="post-body"><div class="post-excerpt"><p><font face="Adobe Caslon Pro"><strong>Learn to Grow: A Continual Structure Learning Framework for<br>
Overcoming Catastrophic Forgetting</strong></font></p>
<p><font face="Adobe Caslon Pro"><em>Xilai Li, Yingbo Zhou, Tianfu Wu, Richard Socher, Caiming Xiong</em></font></p>
<p><font face="Adobe Caslon Pro"><em>ICML 2019</em> </font></p>
<p><font face="Adobe Caslon Pro">[<span class="exturl"><a class="exturl__link" target="_blank" rel="noopener" href="http://proceedings.mlr.press/v97/li19m.html">paper</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>]</font></p></div><div class="post-readmore"><a class="post-readmore__link" href="/2020/12/23/Paper-Note-Learn-to-Grow-A-Continual-Structure-Learning-Framework-for-Overcoming-Catastrophic-Forgetting/"><span class="post-readmore__text">Read More</span><span class="post-readmore__icon"><i class="fas fa-long-arrow-alt-right"></i></span></a></div></div></article></section><nav class="paginator"><div class="paginator-inner"><span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/5/">5</a><a class="extend next" rel="next" href="/page/2/"><i class="fas fa-angle-right"></i></a></div></nav></div></div><div class="sidebar-wrap" id="sidebar-wrap"><aside class="sidebar" id="sidebar"><section class="sidebar-toc hide"></section><!-- ov = overview--><section class="sidebar-ov"><div class="sidebar-ov-author"><div class="sidebar-ov-author__avatar"><img class="sidebar-ov-author__avatar_img" src="/assets/avatar/avatar.png" alt="avatar"></div></div><div class="sidebar-ov-social"><a class="sidebar-ov-social-item" href="mailto:ly_liuyang19@qq.com" target="_blank" rel="noopener" data-popover="social.mail" data-popover-pos="up"><span class="sidebar-ov-social-item__icon">Email</span></a></div><div class="sidebar-ov-state"><a class="sidebar-ov-state-item sidebar-ov-state-item--posts" href="/archives/"><div class="sidebar-ov-state-item__count">42</div><div class="sidebar-ov-state-item__name">Archives</div></a><a class="sidebar-ov-state-item sidebar-ov-state-item--tags" href="/tags/"><div class="sidebar-ov-state-item__count">18</div><div class="sidebar-ov-state-item__name">Tags</div></a></div><div class="sidebar-ov-cc"><a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en" target="_blank" rel="noopener" data-popover="Creative Commons" data-popover-pos="up"><img src="/images/cc-by-nc-sa.svg"></a></div></section></aside></div><div class="clearfix"></div></div></main><footer class="footer" id="footer"><div class="footer-inner"><div><span>Copyright © 2021</span><span class="footer__icon"><i class="fas fa-heart"></i></span><span>liuyang-70d12d</span></div><div><span>Powered by <a href="http://hexo.io/" title="Hexo" target="_blank" rel="noopener">Hexo</a></span><span> v5.2.0</span><span class="footer__devider">|</span><span>Theme - <a href="https://github.com/liuyib/hexo-theme-stun/" title="Stun" target="_blank" rel="noopener">Stun</a></span><span> v2.3.0</span></div><div class="busuanzi"><span class="busuanzi-siteuv"><span class="busuanzi-siteuv__icon"><i class="fas fa-user"></i></span><span class="busuanzi-siteuv__info">Visitors</span><span class="busuanzi-siteuv__value" id="busuanzi_value_site_uv"></span></span><span class="busuanzi-sitepv"><span class="busuanzi-siteuv__icon"><i class="fas fa-eye"></i></span><span class="busuanzi-siteuv__info">Views</span><span class="busuanzi-siteuv__value" id="busuanzi_value_site_pv"></span></span></div><div><span id="timeDate">载入天数...</span><span id="times">载入时分秒...</span><script>var now = new Date();
function createtime() {
var grt= new Date("11/09/2020 00:00:00");
now.setTime(now.getTime()+250);
days = (now - grt ) / 1000 / 60 / 60 / 24; dnum = Math.floor(days);
hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum); hnum = Math.floor(hours);
if(String(hnum).length ==1 ){hnum = "0" + hnum;} minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum);
mnum = Math.floor(minutes); if(String(mnum).length ==1 ){mnum = "0" + mnum;}
seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum);
snum = Math.round(seconds); if(String(snum).length ==1 ){snum = "0" + snum;}
document.getElementById("timeDate").innerHTML = "我已来到这个世界 "+dnum+" 天 ";
document.getElementById("times").innerHTML = hnum + " 小时 " + mnum + " 分 " + snum + " 秒";
}
setInterval("createtime()",250);</script></div></div></footer><div class="loading-bar" id="loading-bar"><div class="loading-bar__progress"></div></div><div class="back2top" id="back2top"><span class="back2top__icon"><i class="fas fa-rocket"></i></span></div></div><script src="https://cdn.jsdelivr.net/npm/jquery@v3.4.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@1.5.2/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@1.5.2/velocity.ui.min.js"></script><link href="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.css" rel="stylesheet" type="text/css"><link href="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/contrib/copy-tex.css" rel="stylesheet" type="text/css"><script src="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/contrib/copy-tex.min.js"></script><script src="https://cdn.jsdelivr.net/gh/sukkaw/busuanzi@latest/bsz.pure.mini.js" async></script><script src="/js/utils.js?v=2.3.0"></script><script src="/js/stun-boot.js?v=2.3.0"></script><script src="/js/scroll.js?v=2.3.0"></script><script src="/js/header.js?v=2.3.0"></script><script src="/js/sidebar.js?v=2.3.0"></script></body></html>