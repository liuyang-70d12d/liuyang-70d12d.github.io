<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1"><meta name="format-detection" content="telephone=no"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black"><link rel="icon" href="/assets/favicon/favicon_01/favicon-16x16.png?v=2.3.0" type="image/png" sizes="16x16"><link rel="icon" href="/assets/favicon/favicon_01/favicon-32x32.png?v=2.3.0" type="image/png" sizes="32x32"><meta name="description" content="1982        Stephen Grossberg. How does a brain build a cognitive code? In Studies of mind and brain, pages 1–52. Springer, 1982.                     1989        M. McCloskey and N">
<meta property="og:type" content="article">
<meta property="og:title" content="Reading List: Papers on Continual Learning">
<meta property="og:url" content="https://hello-liuyang.com/2020/11/27/Reading-List-Papers-on-Continual-Learning/index.html">
<meta property="og:site_name" content="Hello, Stranger">
<meta property="og:description" content="1982        Stephen Grossberg. How does a brain build a cognitive code? In Studies of mind and brain, pages 1–52. Springer, 1982.                     1989        M. McCloskey and N">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2020-11-27T00:47:15.000Z">
<meta property="article:modified_time" content="2020-12-02T02:24:39.660Z">
<meta property="article:author" content="liuyang-70d12d">
<meta property="article:tag" content="Continual Learning">
<meta name="twitter:card" content="summary"><title>Reading List: Papers on Continual Learning | Hello, Stranger</title><link ref="canonical" href="https://hello-liuyang.com/2020/11/27/Reading-List-Papers-on-Continual-Learning/"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.12.1/css/all.min.css" type="text/css"><link rel="stylesheet" href="/css/index.css?v=2.3.0"><script>var Stun = window.Stun || {};
var CONFIG = {
  root: '/',
  algolia: undefined,
  assistSearch: undefined,
  fontIcon: {"prompt":{"success":"fas fa-check-circle","info":"fas fa-arrow-circle-right","warning":"fas fa-exclamation-circle","error":"fas fa-times-circle"},"copyBtn":"fas fa-copy"},
  sidebar: {"offsetTop":"20px","tocMaxDepth":6},
  header: {"enable":true,"showOnPost":false,"scrollDownIcon":true},
  postWidget: {"endText":true},
  nightMode: {"enable":true},
  back2top: {"enable":true},
  codeblock: {"style":"default","highlight":"light","wordWrap":false},
  reward: false,
  fancybox: false,
  zoomImage: {"gapAside":"20px"},
  galleryWaterfall: undefined,
  lazyload: false,
  pjax: undefined,
  externalLink: {"icon":{"enable":true,"name":"fas fa-external-link-alt"}},
  shortcuts: undefined,
  prompt: {"copyButton":"Copy","copySuccess":"Copy Success","copyError":"Copy Error"},
  sourcePath: {"js":"js","css":"css","images":"images"},
};

window.CONFIG = CONFIG;</script><meta name="generator" content="Hexo 5.2.0"></head><body><div class="container" id="container"><header class="header" id="header"><div class="header-inner header-inner--height header-inner--bgcolor"><nav class="header-nav header-nav--sticky"><div class="header-nav-inner"><div class="header-nav-menubtn"><i class="fas fa-bars"></i></div><div class="header-nav-menu"><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/"><span class="header-nav-menu-item__icon"><i class="fas fa-home"></i></span><span class="header-nav-menu-item__text">Home</span></a></div><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/archives/"><span class="header-nav-menu-item__icon"><i class="fas fa-folder-open"></i></span><span class="header-nav-menu-item__text">Archives</span></a></div><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/tags/"><span class="header-nav-menu-item__icon"><i class="fas fa-tags"></i></span><span class="header-nav-menu-item__text">Tags</span></a></div></div><div class="header-nav-mode"><div class="mode"><div class="mode-track"><span class="mode-track-moon"></span><span class="mode-track-sun"></span></div><div class="mode-thumb"></div></div></div></div></nav></div></header><main class="main" id="main"><div class="main-inner"><div class="content-wrap" id="content-wrap"><div class="content" id="content"><!-- Just used to judge whether it is an article page--><div id="is-post"></div><div class="post"><header class="post-header"><h1 class="post-title">Reading List: Papers on Continual Learning</h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">Created</span><span class="post-meta-item__value">2020-11-27</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">Updated</span><span class="post-meta-item__value">2020-12-02</span></span><span class="post-meta-item post-meta-item--visitors"><span class="post-meta-item__icon"><i class="fas fa-eye"></i></span><span class="post-meta-item__info">Visited</span><span class="post-meta-item__value" id="busuanzi_value_page_pv"></span></span></div></header><div class="post-body">
        <h4 id="1982">
          <a href="#1982" class="heading-link"><i class="fas fa-link"></i></a>1982</h4>
      
<p><font face="Adobe Caslon Pro" color="grey">Stephen Grossberg. How does a brain build a cognitive code? In Studies of mind and brain, pages 1–52. Springer, 1982.</font></p>

        <h4 id="1989">
          <a href="#1989" class="heading-link"><i class="fas fa-link"></i></a>1989</h4>
      
<p><font face="Adobe Caslon Pro" color="grey">M. McCloskey and N. J. Cohen. Catastrophic interference in connectionist networks: The sequential learning problem. Psychology of learning and motivation, 24:109–165, 1989.</font></p>
<p><font face="Adobe Caslon Pro" color="grey"></font></p>

        <h4 id="1997">
          <a href="#1997" class="heading-link"><i class="fas fa-link"></i></a>1997</h4>
      
<p><font face="Adobe Caslon Pro" color="grey">Mark B Ring. Child: A first step towards continual learning. Machine Learning, 28(1):77–104, 1997.</font></p>

        <h4 id="2002">
          <a href="#2002" class="heading-link"><i class="fas fa-link"></i></a>2002</h4>
      
<p><font face="Adobe Caslon Pro" color="grey">D. L. Silver and R. E. Mercer, “The task rehearsal method of life-long learning: Overcoming impoverished data,” in Conference of the Canadian Society for Computational Studies of Intelligence. Springer, 2002, pp. 90–101.</font></p>

        <h4 id="2005">
          <a href="#2005" class="heading-link"><i class="fas fa-link"></i></a>2005</h4>
      
<p><font face="Adobe Caslon Pro" color="grey">O.-M. Moe-Helgesen and H. Stranden. Catastophic forgetting in neural networks. Technical report, Norwegian University of Science and Technology (NTNU), 2005.</font></p>

        <h4 id="2013">
          <a href="#2013" class="heading-link"><i class="fas fa-link"></i></a>2013</h4>
      
<p><font face="Adobe Caslon Pro" color="grey">I. J. Goodfellow, M. Mirza, D. Xiao, A. Courville, and Y. Bengio, “An empirical investigation of catastrophic forgetting in gradient-based neural networks,” arXiv preprint arXiv:1312.6211, 2013.</font></p>
<p><font face="Adobe Caslon Pro" color="grey">I. Kuzborskij, F. Orabona, and B. Caputo. From n to n + 1: Multiclass transfer incremental learning. In Conference on Computer Vision and Pattern Recognition (CVPR), 2013.</font></p>
<p><font face="Adobe Caslon Pro" color="grey"></font></p>

        <h4 id="2014">
          <a href="#2014" class="heading-link"><i class="fas fa-link"></i></a>2014</h4>
      
<p><font face="Adobe Caslon Pro" color="grey">M. Ristin, M. Guillaumin, J. Gall, and L. Van Gool. Incremental learning of NCM forests for large-scale image classification. In Conference on Computer Vision and Pattern Recognition (CVPR), 2014.</font></p>
<p><font face="Adobe Caslon Pro" color="grey">I. J. Goodfellow, M. Mirza, D. Xiao, A. Courville, and Y. Bengio. An empirical investigation of catastrophic forgeting in gradient-based neural networks. In International Conference on Learning Representations (ICLR), 2014.</font></p>
<p><font face="Adobe Caslon Pro" color="grey">T. Xiao, J. Zhang, K. Yang, Y. Peng, and Z. Zhang. Error-driven incremental learning in deep convolutional neural network for large-scale image classification. In International Conference on Multimedia (ACM MM), 2014.</font></p>
<p><font face="Adobe Caslon Pro" color="grey"></font></p>
<p><font face="Adobe Caslon Pro" color="grey"></font></p>

        <h4 id="2016">
          <a href="#2016" class="heading-link"><i class="fas fa-link"></i></a>2016</h4>
      
<p><font face="Adobe Caslon Pro" color="grey">Andrei A Rusu, Neil C Rabinowitz, Guillaume Desjardins, Hubert Soyer, James Kirkpatrick, Koray Kavukcuoglu, Razvan Pascanu, and Raia Hadsell. Progressive neural networks. arXiv preprint arXiv:1606.04671, 2016.</font></p>
<p><font face="Adobe Caslon Pro" color="grey">A. Gepperth and C. Karaoguz, “A bio-inspired incremental learning architecture for applied perceptual problems,” Cognitive Computation, vol. 8, no. 5, pp. 924–934, 2016.</font></p>
<p><font face="Adobe Caslon Pro" color="grey">Z. Li and D. Hoiem. Learning without forgetting. In European Conference on Computer Vision (ECCV), 2016.</font></p>
<p><font face="Adobe Caslon Pro" color="grey">Kieran Milan, Joel Veness, James Kirkpatrick, Michael Bowling, Anna Koop, and Demis Hassabis. The forget-me-not process. In NeurIPS, 2016.</font></p>
<p><font face="Adobe Caslon Pro" color="grey"></font></p>
<p><font face="Adobe Caslon Pro" color="grey"></font></p>

        <h4 id="2017">
          <a href="#2017" class="heading-link"><i class="fas fa-link"></i></a>2017</h4>
      
<p><font face="Adobe Caslon Pro" color="grey">James N Kirkpatrick, Razvan Pascanu, Neil C. Rabinowitz, Joel Veness, and et. al. Overcoming catastrophic forgetting in neural networks. Proceedings of the National Academy of Sciences of the United States of America, 114 13:3521–3526, 2017.</font></p>
<p><font face="Adobe Caslon Pro" color="grey">Hanul Shin, Jung Kwon Lee, Jaehong Kim, and Jiwon Kim. Continual learning with deep generative replay. In Advances in Neural Information Processing Systems, pp. 2990–2999, 2017.</font></p>
<p><font face="Adobe Caslon Pro" color="grey">Friedemann Zenke, Ben Poole, and Surya Ganguli. Continual learning through synaptic intelligence. In Proceedings of the 34th International Conference on Machine Learning-Volume 70, pp. 3987–3995. JMLR, 2017.</font></p>
<p><font face="Adobe Caslon Pro" color="grey">David Lopez-Paz and Marc’Aurelio Ranzato. Gradient episodic memory for continual learning. In Advances in Neural Information Processing Systems, pp. 6467–6476, 2017.</font></p>
<p><font face="Adobe Caslon Pro" color="grey">R. Aljundi, P. Chakravarty, and T. Tuytelaars, “Expert gate: Lifelong learning with a network of experts,” in CVPR, 2017, pp. 3366–3375.</font></p>
<p><font face="Adobe Caslon Pro" color="grey">A. Rannen, R. Aljundi, M. B. Blaschko, and T. Tuytelaars, “Encoder based lifelong learning,” in ICCV, 2017, pp. 1320–1328.</font></p>
<p><font face="Adobe Caslon Pro" color="grey">S.-W. Lee, J.-H. Kim, J. Jun, J.-W. Ha, and B.-T. Zhang, “Overcoming catastrophic forgetting by incremental moment matching,” in NeurIPS, 2017, pp. 4652–4662.</font></p>
<p><font face="Adobe Caslon Pro" color="grey">C. Fernando, D. Banarse, C. Blundell, Y. Zwols, D. Ha, A. A.Rusu, A. Pritzel, and D. Wierstra, “Pathnet: Evolution channels gradient descent in super neural networks,” arXiv preprint arXiv:1701.08734, 2017.</font></p>
<p>√  <font face="Adobe Caslon Pro"><a href="https://hello-liuyang.com/2020/11/30/Paper-Note-iCaRL-Incremental-Classifier-and-Representation-Learning/">S.-A. Rebuffi, A. Kolesnikov, G. Sperl, and C. H. Lampert, “icarl: Incremental classifier and representation learning,” in CVPR, 2017, pp. 2001–2010.</a></font></p>
<p><font face="Adobe Caslon Pro" color="grey"></font></p>
<p><font face="Adobe Caslon Pro" color="grey"></font></p>
<p><font face="Adobe Caslon Pro" color="grey"></font></p>

        <h4 id="2018">
          <a href="#2018" class="heading-link"><i class="fas fa-link"></i></a>2018</h4>
      
<p><font face="Adobe Caslon Pro" color="grey">Ronald Kemker, Marc McClure, Angelina Abitino, Tyler L Hayes, and Christopher Kanan. Measuring catastrophic forgetting in neural networks. In Thirty-second AAAI conference on artificial intelligence, 2018.</font></p>
<p><font face="Adobe Caslon Pro" color="grey">German Ignacio Parisi, Ronald Kemker, Jose L. Part, Christopher Kanan, and Stefan Wermter. Continual lifelong learning with neural networks: A review. 2018.</font></p>
<p><font face="Adobe Caslon Pro" color="grey">Mariya Toneva, Alessandro Sordoni, Remi Tachet des Combes, Adam Trischler, Yoshua Bengio, and Geoffrey J Gordon. An empirical study of example forgetting during deep neural network learning. arXiv preprint arXiv:1812.05159, 2018.</font></p>
<p><font face="Adobe Caslon Pro" color="grey">Yen-Chang Hsu, Yen-Cheng Liu, and Zsolt Kira. Re-evaluating continual learning scenarios: A categorization and case for strong baselines. arXiv preprint arXiv:1810.12488, 2018.</font></p>
<p><font face="Adobe Caslon Pro" color="grey"> Rolnick, David, et al. “Experience replay for continual learning.” <em>Advances in Neural Information Processing Systems</em>. 2019. </font></p>
<p><font face="Adobe Caslon Pro" color="grey">Arslan Chaudhry, Marc’Aurelio Ranzato, Marcus Rohrbach, and Mohamed Elhoseiny. Efficient lifelong learning with a-gem. ArXiv, abs/1812.00420, 2018b.</font></p>
<p><font face="Adobe Caslon Pro" color="grey">Matthew Riemer, Ignacio Cases, Robert Ajemian, Miao Liu, Irina Rish, Yuhai Tu, and Gerald Tesauro. Learning to learn without forgetting by maximizing transfer and minimizing interference. arXiv preprint arXiv:1810.11910, 2018.</font></p>
<p><font face="Adobe Caslon Pro" color="grey">Z. Chen and B. Liu, “Lifelong machine learning,” Synthesis Lectures on Artificial Intelligence and Machine Learning, vol. 12, no. 3, pp. 1–207, 2018.</font></p>
<p><font face="Adobe Caslon Pro" color="grey">S. Farquhar and Y. Gal, “Towards robust evaluations of continual learning,” arXiv preprint arXiv:1805.09733, 2018.</font></p>
<p><font face="Adobe Caslon Pro" color="grey">Jonathan Schwarz, Jelena Luketina, Wojciech M Czarnecki, Agnieszka Grabska-Barwinska, Yee Whye Teh, Razvan Pascanu, and Raia Hadsell. Progress &amp; compress: A scalable framework for continual learning. In ICML, 2018.</font></p>
<p><font face="Adobe Caslon Pro" color="grey">Christos Kaplanis, Murray Shanahan, and Claudia Clopath. Continual reinforcement learning with complex synapses. In ICML, 2018.</font></p>
<p><font face="Adobe Caslon Pro" color="grey">David Isele and Akansel Cosgun. Selective experience replay for lifelong learning. In AAAI, 2018.</font></p>
<p><font face="Adobe Caslon Pro" color="grey"></font></p>

        <h4 id="2019">
          <a href="#2019" class="heading-link"><i class="fas fa-link"></i></a>2019</h4>
      
<p><font face="Adobe Caslon Pro" color="grey">Arslan Chaudhry, Albert Gordo, Puneet Kumar Dokania, Philip H. S. Torr, and David Lopez-Paz. Using hindsight to anchor past knowledge in continual learning. ArXiv, abs/2002.08165, 2019.</font></p>
<p><font face="Adobe Caslon Pro" color="grey">Michalis K Titsias, Jonathan Schwarz, Alexander G de G Matthews, Razvan Pascanu, and Yee Whye Teh. Functional regularisation for continual learning using gaussian processes. arXiv preprint arXiv:1901.11356, 2019.</font></p>
<p><font face="Adobe Caslon Pro" color="grey">Matthias Lange, Rahaf Aljundi, Marc Masana, Sarah Parisot, Xu Jia, Ale Leonardis, Gregory G.Slabaugh, and Tinne Tuytelaars. A continual learning survey: Defying forgetting in classification tasks. ArXiv, abs/1909.08383, 2019.</font></p>
<p><font face="Adobe Caslon Pro" color="grey">Cuong V Nguyen, Alessandro Achille, Michael Lam, Tal Hassner, Vijay Mahadevan, and Stefano Soatto. Toward understanding catastrophic forgetting in continual learning. arXiv preprint arXiv:1908.01091, 2019.</font></p>
<p><font face="Adobe Caslon Pro" color="grey">Mehrdad Farajtabar, Navid Azizan, Alex Mott, and Ang Li. Orthogonal gradient descent for continual learning. ArXiv, abs/1910.07104, 2019.</font></p>
<p><font face="Adobe Caslon Pro" color="grey">Xilai Li, Yingbo Zhou, Tianfu Wu, Richard Socher, and Caiming Xiong. Learn to grow: A continual structure learning framework for overcoming catastrophic forgetting. arXiv preprint arXiv:1904.00310, 2019.</font></p>
<p><font face="Adobe Caslon Pro" color="grey">A. Chaudhry, M. Ranzato, M. Rohrbach, and M. Elhoseiny, “Efficient lifelong learning with A-GEM,” in ICLR, 2019. [Online]. Available: <span class="exturl"><a class="exturl__link" target="_blank" rel="noopener" href="https://openreview.net/forum?id=Hkf2_sC5FX">https://openreview.net/forum?id=Hkf2_sC5FX</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></font></p>
<p><font face="Adobe Caslon Pro" color="grey">G. I. Parisi, R. Kemker, J. L. Part, C. Kanan, and S. Wermter, “Continual lifelong learning with neural networks: A review,” Neural Networks, 2019.</font></p>
<p><font face="Adobe Caslon Pro" color="grey"> Pfülb, Benedikt, and Alexander Gepperth. “A comprehensive, application-oriented study of catastrophic forgetting in dnns.” <em>arXiv preprint arXiv:1905.08101</em> (2019). </font></p>
<p><font face="Adobe Caslon Pro" color="grey">Christos Kaplanis, Murray Shanahan, and Claudia Clopath. Policy consolidation for continual reinforcement learning. In ICML, 2019.</font></p>
<p><font face="Adobe Caslon Pro" color="grey"></font></p>
<p><font face="Adobe Caslon Pro" color="grey"></font></p>

        <h4 id="2020">
          <a href="#2020" class="heading-link"><i class="fas fa-link"></i></a>2020</h4>
      
<p><font face="Adobe Caslon Pro" color="grey">Dong Yin, Mehrdad Farajtabar, and Ang Li. SOLA: Continual learning with second-order loss approximation. arXiv preprint arXiv:2006.10974, 2020.</font></p>
<p><font face="Adobe Caslon Pro" color="grey">Seyed-Iman Mirzadeh, Mehrdad Farajtabar, and Hassan Ghasemzadeh. Dropout as an implicit gating mechanism for continual learning. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops, pp. 232–233, 2020.</font></p>
<p><font face="Adobe Caslon Pro" color="grey">Matthew Wallingford, Aditya Kusupati, Keivan Alizadeh-Vahid, Aaron Walsman, Aniruddha Kembhavi, and Ali Farhadi. In the wild: From ml models to pragmatic ml systems. ArXiv, abs/2007.02519, 2020.</font></p>
<p><font face="Adobe Caslon Pro" color="grey"></font></p>
</div><footer class="post-footer"><div class="post-ending ending"><div class="ending__text">------ END ------</div></div><div class="post-copyright copyright"><div class="copyright-author"><span class="copyright-author__name">Author: </span><span class="copyright-author__value"><a href="https://hello-liuyang.com">liuyang-70d12d</a></span></div><div class="copyright-link"><span class="copyright-link__name">Link: </span><span class="copyright-link__value"><a href="https://hello-liuyang.com/2020/11/27/Reading-List-Papers-on-Continual-Learning/">https://hello-liuyang.com/2020/11/27/Reading-List-Papers-on-Continual-Learning/</a></span></div><div class="copyright-notice"><span class="copyright-notice__name">Copyright: </span><span class="copyright-notice__value">All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en" rel="external nofollow" target="_blank">BY-NC-SA</a> unless stating additionally</span></div></div><div class="post-tags"><span class="post-tags-item"><span class="post-tags-item__icon"><i class="fas fa-tag"></i></span><a class="post-tags-item__link" href="https://hello-liuyang.com/tags/Continual-Learning/">Continual Learning</a></span></div><nav class="post-paginator paginator"><div class="paginator-prev"><a class="paginator-prev__link" href="/2020/11/27/Paper-Note-A-continual-learning-survey-Defying-forgetting-in-classification-tasks/"><span class="paginator-prev__icon"><i class="fas fa-angle-left"></i></span><span class="paginator-prev__text">Paper Note: A continual learning survey: Defying forgetting in classification tasks</span></a></div><div class="paginator-next"><a class="paginator-next__link" href="/2020/11/26/Paper-Note-Linear-Mode-Connectivity-in-Multitask-and-Continual-Learning/"><span class="paginator-prev__text">Paper Note: Linear Mode Connectivity in Multitask and Continual Learning</span><span class="paginator-next__icon"><i class="fas fa-angle-right"></i></span></a></div></nav></footer></div></div></div><div class="sidebar-wrap" id="sidebar-wrap"><aside class="sidebar" id="sidebar"><div class="sidebar-nav"><span class="sidebar-nav-toc current">Catalog</span><span class="sidebar-nav-ov">Overview</span></div><section class="sidebar-toc"><ol class="toc"><li class="toc-item toc-level-4"><a class="toc-link" href="#1982"><span class="toc-number">1.</span> <span class="toc-text">
          1982</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1989"><span class="toc-number">2.</span> <span class="toc-text">
          1989</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1997"><span class="toc-number">3.</span> <span class="toc-text">
          1997</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2002"><span class="toc-number">4.</span> <span class="toc-text">
          2002</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2005"><span class="toc-number">5.</span> <span class="toc-text">
          2005</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2013"><span class="toc-number">6.</span> <span class="toc-text">
          2013</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2014"><span class="toc-number">7.</span> <span class="toc-text">
          2014</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2016"><span class="toc-number">8.</span> <span class="toc-text">
          2016</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2017"><span class="toc-number">9.</span> <span class="toc-text">
          2017</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2018"><span class="toc-number">10.</span> <span class="toc-text">
          2018</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2019"><span class="toc-number">11.</span> <span class="toc-text">
          2019</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2020"><span class="toc-number">12.</span> <span class="toc-text">
          2020</span></a></li></ol></section><!-- ov = overview--><section class="sidebar-ov hide"><div class="sidebar-ov-author"><div class="sidebar-ov-author__avatar"><img class="sidebar-ov-author__avatar_img" src="/assets/avatar/avatar.png" alt="avatar"></div></div><div class="sidebar-ov-social"><a class="sidebar-ov-social-item" href="mailto:ly_liuyang19@qq.com" target="_blank" rel="noopener" data-popover="social.mail" data-popover-pos="up"><span class="sidebar-ov-social-item__icon">Email</span></a></div><div class="sidebar-ov-state"><a class="sidebar-ov-state-item sidebar-ov-state-item--posts" href="/archives/"><div class="sidebar-ov-state-item__count">15</div><div class="sidebar-ov-state-item__name">Archives</div></a><a class="sidebar-ov-state-item sidebar-ov-state-item--tags" href="/tags/"><div class="sidebar-ov-state-item__count">14</div><div class="sidebar-ov-state-item__name">Tags</div></a></div><div class="sidebar-ov-cc"><a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en" target="_blank" rel="noopener" data-popover="Creative Commons" data-popover-pos="up"><img src="/images/cc-by-nc-sa.svg"></a></div></section><div class="sidebar-reading"><div class="sidebar-reading-info"><span class="sidebar-reading-info__text">You have read </span><span class="sidebar-reading-info__num">0</span><span class="sidebar-reading-info__perc">%</span></div><div class="sidebar-reading-line"></div></div></aside></div><div class="clearfix"></div></div></main><footer class="footer" id="footer"><div class="footer-inner"><div><span>Copyright © 2020</span><span class="footer__icon"><i class="fas fa-heart"></i></span><span>liuyang-70d12d</span></div><div><span>Powered by <a href="http://hexo.io/" title="Hexo" target="_blank" rel="noopener">Hexo</a></span><span> v5.2.0</span><span class="footer__devider">|</span><span>Theme - <a href="https://github.com/liuyib/hexo-theme-stun/" title="Stun" target="_blank" rel="noopener">Stun</a></span><span> v2.3.0</span></div><div class="busuanzi"><span class="busuanzi-siteuv"><span class="busuanzi-siteuv__icon"><i class="fas fa-user"></i></span><span class="busuanzi-siteuv__info">Visitors</span><span class="busuanzi-siteuv__value" id="busuanzi_value_site_uv"></span></span><span class="busuanzi-sitepv"><span class="busuanzi-siteuv__icon"><i class="fas fa-eye"></i></span><span class="busuanzi-siteuv__info">Views</span><span class="busuanzi-siteuv__value" id="busuanzi_value_site_pv"></span></span></div><div><span id="timeDate">载入天数...</span><span id="times">载入时分秒...</span><script>var now = new Date();
function createtime() {
var grt= new Date("11/09/2020 00:00:00");
now.setTime(now.getTime()+250);
days = (now - grt ) / 1000 / 60 / 60 / 24; dnum = Math.floor(days);
hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum); hnum = Math.floor(hours);
if(String(hnum).length ==1 ){hnum = "0" + hnum;} minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum);
mnum = Math.floor(minutes); if(String(mnum).length ==1 ){mnum = "0" + mnum;}
seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum);
snum = Math.round(seconds); if(String(snum).length ==1 ){snum = "0" + snum;}
document.getElementById("timeDate").innerHTML = "我已来到这个世界 "+dnum+" 天 ";
document.getElementById("times").innerHTML = hnum + " 小时 " + mnum + " 分 " + snum + " 秒";
}
setInterval("createtime()",250);</script></div></div></footer><div class="loading-bar" id="loading-bar"><div class="loading-bar__progress"></div></div><div class="back2top" id="back2top"><span class="back2top__icon"><i class="fas fa-rocket"></i></span></div></div><script src="https://cdn.jsdelivr.net/npm/jquery@v3.4.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@1.5.2/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@1.5.2/velocity.ui.min.js"></script><link href="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.css" rel="stylesheet" type="text/css"><link href="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/contrib/copy-tex.css" rel="stylesheet" type="text/css"><script src="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/contrib/copy-tex.min.js"></script><script src="https://cdn.jsdelivr.net/gh/sukkaw/busuanzi@latest/bsz.pure.mini.js" async></script><script src="/js/utils.js?v=2.3.0"></script><script src="/js/stun-boot.js?v=2.3.0"></script><script src="/js/scroll.js?v=2.3.0"></script><script src="/js/header.js?v=2.3.0"></script><script src="/js/sidebar.js?v=2.3.0"></script></body></html>