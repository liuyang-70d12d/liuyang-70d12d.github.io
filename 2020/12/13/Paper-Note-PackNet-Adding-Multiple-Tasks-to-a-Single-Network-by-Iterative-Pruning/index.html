<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1"><meta name="format-detection" content="telephone=no"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black"><link rel="icon" href="/assets/favicon/favicon_01/favicon-16x16.png?v=2.3.0" type="image/png" sizes="16x16"><link rel="icon" href="/assets/favicon/favicon_01/favicon-32x32.png?v=2.3.0" type="image/png" sizes="32x32"><meta name="description" content="PackNet: Adding Multiple Tasks to a Single Network by Iterative Pruning Arun Mallya, Svetlana Lazebnik CVPR 2018  [paper] [code]">
<meta property="og:type" content="article">
<meta property="og:title" content="Paper Note: PackNet: Adding Multiple Tasks to a Single Network by Iterative Pruning">
<meta property="og:url" content="https://hello-liuyang.com/2020/12/13/Paper-Note-PackNet-Adding-Multiple-Tasks-to-a-Single-Network-by-Iterative-Pruning/index.html">
<meta property="og:site_name" content="Hello, Stranger">
<meta property="og:description" content="PackNet: Adding Multiple Tasks to a Single Network by Iterative Pruning Arun Mallya, Svetlana Lazebnik CVPR 2018  [paper] [code]">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://hello-liuyang.com/2020/12/13/Paper-Note-PackNet-Adding-Multiple-Tasks-to-a-Single-Network-by-Iterative-Pruning/01.png">
<meta property="article:published_time" content="2020-12-13T13:04:24.000Z">
<meta property="article:modified_time" content="2021-01-17T07:10:36.283Z">
<meta property="article:author" content="liuyang-70d12d">
<meta property="article:tag" content="Continual Learning">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://hello-liuyang.com/2020/12/13/Paper-Note-PackNet-Adding-Multiple-Tasks-to-a-Single-Network-by-Iterative-Pruning/01.png"><title>Paper Note: PackNet: Adding Multiple Tasks to a Single Network by Iterative Pruning | Hello, Stranger</title><link ref="canonical" href="https://hello-liuyang.com/2020/12/13/Paper-Note-PackNet-Adding-Multiple-Tasks-to-a-Single-Network-by-Iterative-Pruning/"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.12.1/css/all.min.css" type="text/css"><link rel="stylesheet" href="/css/index.css?v=2.3.0"><script>var Stun = window.Stun || {};
var CONFIG = {
  root: '/',
  algolia: undefined,
  assistSearch: undefined,
  fontIcon: {"prompt":{"success":"fas fa-check-circle","info":"fas fa-arrow-circle-right","warning":"fas fa-exclamation-circle","error":"fas fa-times-circle"},"copyBtn":"fas fa-copy"},
  sidebar: {"offsetTop":"20px","tocMaxDepth":6},
  header: {"enable":true,"showOnPost":false,"scrollDownIcon":true},
  postWidget: {"endText":true},
  nightMode: {"enable":true},
  back2top: {"enable":true},
  codeblock: {"style":"default","highlight":"light","wordWrap":false},
  reward: false,
  fancybox: false,
  zoomImage: {"gapAside":"20px"},
  galleryWaterfall: undefined,
  lazyload: false,
  pjax: undefined,
  externalLink: {"icon":{"enable":true,"name":"fas fa-external-link-alt"}},
  shortcuts: undefined,
  prompt: {"copyButton":"Copy","copySuccess":"Copy Success","copyError":"Copy Error"},
  sourcePath: {"js":"js","css":"css","images":"images"},
};

window.CONFIG = CONFIG;</script><meta name="generator" content="Hexo 5.2.0"></head><body><div class="container" id="container"><header class="header" id="header"><div class="header-inner header-inner--height header-inner--bgcolor"><nav class="header-nav header-nav--sticky"><div class="header-nav-inner"><div class="header-nav-menubtn"><i class="fas fa-bars"></i></div><div class="header-nav-menu"><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/"><span class="header-nav-menu-item__icon"><i class="fas fa-home"></i></span><span class="header-nav-menu-item__text">Home</span></a></div><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/archives/"><span class="header-nav-menu-item__icon"><i class="fas fa-folder-open"></i></span><span class="header-nav-menu-item__text">Archives</span></a></div><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/tags/"><span class="header-nav-menu-item__icon"><i class="fas fa-tags"></i></span><span class="header-nav-menu-item__text">Tags</span></a></div></div><div class="header-nav-mode"><div class="mode"><div class="mode-track"><span class="mode-track-moon"></span><span class="mode-track-sun"></span></div><div class="mode-thumb"></div></div></div></div></nav></div></header><main class="main" id="main"><div class="main-inner"><div class="content-wrap" id="content-wrap"><div class="content" id="content"><!-- Just used to judge whether it is an article page--><div id="is-post"></div><div class="post"><header class="post-header"><h1 class="post-title">Paper Note: PackNet: Adding Multiple Tasks to a Single Network by Iterative Pruning</h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">Created</span><span class="post-meta-item__value">2020-12-13</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">Updated</span><span class="post-meta-item__value">2021-01-17</span></span><span class="post-meta-item post-meta-item--visitors"><span class="post-meta-item__icon"><i class="fas fa-eye"></i></span><span class="post-meta-item__info">Visited</span><span class="post-meta-item__value" id="busuanzi_value_page_pv"></span></span></div></header><div class="post-body"><p><font face="Adobe Caslon Pro"><strong>PackNet: Adding Multiple Tasks to a Single Network by Iterative Pruning</strong></font></p>
<p><font face="Adobe Caslon Pro"><em>Arun Mallya, Svetlana Lazebnik</em></font></p>
<p><font face="Adobe Caslon Pro"><em>CVPR 2018</em> </font></p>
<p><font face="Adobe Caslon Pro">[<span class="exturl"><a class="exturl__link" target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content_cvpr_2018/html/Mallya_PackNet_Adding_Multiple_CVPR_2018_paper.html">paper</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>]</font> <font face="Adobe Caslon Pro">[<span class="exturl"><a class="exturl__link" target="_blank" rel="noopener" href="https://github.com/arunmallya/packnet">code</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>]</font></p>
<a id="more"></a>

        <h2 id="font-faceadobe-caslon-promain-ideafont">
          <a href="#font-faceadobe-caslon-promain-ideafont" class="heading-link"><i class="fas fa-link"></i></a>Main Idea</h2>
      
<p><font face="Adobe Caslon Pro">文章提出了一种新的持续学习方法，即以对准确率尽可能小的损失为代价，使用基于权重的剪枝技术来释放掉训练完一个任务后冗余的模型参数。然后将未被减枝的参数固定住，被减枝的参数就会被用来学习新的任务。通过使用由剪枝得到的 task-specific parameter masks，我们的模型即便在经历了多个任务之后依然能够保持与初始时相同水准的准确率，并且对于每个新任务而言只产生很小的存储开销。</font></p>
<img src="/2020/12/13/Paper-Note-PackNet-Adding-Multiple-Tasks-to-a-Single-Network-by-Iterative-Pruning/01.png" class>
<p><font face="Adobe Caslon Pro">Figure 1. 以一个 5×5 的 filter 为例说明本方法的训练过程。(a) 在任务 I 上进行初始训练，学习得到一个完整的filter；(b) 裁剪掉 60% (15/25) 再重新训练，得到了一个对应于任务 I 的稀疏的 filter，其中白圆圈代表0值权重，对应于任务 I 的权重将被固定，并且不会在后续过程中被裁剪；© 被剪枝的权重可以用于学习任务 II；(d) 再减枝33%(5/15)并且重新训练，橘色的圆圈即代表对应于任务 II 的权重，随即也被固定，并且之后不会被剪枝。这个过程将会随着学习完所有任务或者使用完所有filter 而终止。在推断时，根据所选的任务使用对应的mask。</font></p>

        <h2 id="font-faceadobe-caslon-prorelated-workfont">
          <a href="#font-faceadobe-caslon-prorelated-workfont" class="heading-link"><i class="fas fa-link"></i></a>Related Work</h2>
      
<p><font face="Adobe Caslon Pro">本文与LwF和EWC做了个简单的比较：与LwF和EWC相同之处在于，PackNet 也不需要存储旧任务的数据。与EWC的想法相似，都是想避免改变对于之前任务重要的参数。EWC用的是一个 soft constraint，而PackNet是使用剪枝技术来识别出最重要的参数。PackNet的优点在于，如果后续的任务与之前的任务很不相关，也完全不会影响到之前任务的性能。</font></p>
<p><font face="Adobe Caslon Pro">本文与 ProgNet [26] 的比较：ProgNet 的缺点在于，随着所遇到的任务数量不断增加，整个网络的规模也会随之不断增加。而PackNet也会随着任务数量的增加而增加存储开销，但是相比之下就小很多，因为对于每一个任务都只存储一个二值参数选择mask。</font></p>
<p><font face="Adobe Caslon Pro">本文与 PathNet [3] 的比较：PackNet 和 PathNet 要做的事情很像，都是从一个固定大小的神经网络里面，把与任务相关的参数摘出来。但是PathNet需要对pathway进行计算密集的搜索，而 PackNet 不需要。</font></p>
<p><font face="Adobe Caslon Pro"></font></p>
<p><font face="Adobe Caslon Pro">像本文这一类的持续学习方法是走的模型压缩的思想路线。我们的工作与最近 Han <em>et al.</em> [7] 提出的方法非常相关，该方法是说通过使网络稀疏并再次训练网络的权重，可以视作是一种正则化的方式，能够改善在同一个任务上的性能。</font></p>
<p><font face="Adobe Caslon Pro">这篇论文研究的是 task incremental learning。</font></p>

        <h2 id="font-faceadobe-caslon-promethodfont">
          <a href="#font-faceadobe-caslon-promethodfont" class="heading-link"><i class="fas fa-link"></i></a>Method</h2>
      
<p><font face="Adobe Caslon Pro">论文最基本的想法就是在固定网络大小不变的情况下，通过剪枝使一些参数成为 free parameters，以便能使它们被用来训练新的任务。</font></p>

        <h3 id="font-faceadobe-caslon-protrainingfont">
          <a href="#font-faceadobe-caslon-protrainingfont" class="heading-link"><i class="fas fa-link"></i></a>Training</h3>
      
<p><font face="Adobe Caslon Pro">Figure 1已经说得很明白了。我们从为初始任务学习的一个标准网络开始，称作 Task I。filter 的初始权重在 Figure 1 (a) 中用灰色表示。然后，我们裁剪掉一部分网络权重（即：将其置为0）。由于网络连接的突然变化，裁剪网络会导致性能下降。当裁剪率很高时，这一点尤其明显。为了在裁剪后恢复准确率，我们需要对网络进行重新训练，所需的 epochs 要比初始训练时所需的少。经过一轮裁剪和重新训练后，我们获得了一个具有稀疏 filter 的网络，并且对 Task I 的性能影响降到了最低。TaskI的surviving parameters（未被裁剪的参数，即 Figure 1 (b) 中灰色的参数）此后保持不变。</font></p>
<p><font face="Adobe Caslon Pro">接下来，我们为新任务 Task II 训练网络，使裁剪后的权重从0恢复，获得 Figure 1 © 所示的橙色权重。注意，Task II的 filters 同时使用了灰色和橙色权重——即，重复使用了属于先前任务的权重。我们再次裁剪网络，释放掉一些仅用于 Task II 的参数，并重新训练 Task II 以从裁剪中恢复。 最终的 filters 如 Figure 1 (d) 所示。此后，Task I 和 Task II 的权重保持固定，然后将可被裁剪的参数用于学习又一个新任务，从而得到如 Figure 1 (e) 所示的绿色权重。重复此过程，直到完成了所有任务或没有更多可用的 free parameters 为止。</font></p>

        <h3 id="font-faceadobe-caslon-propruning-procedurefont">
          <a href="#font-faceadobe-caslon-propruning-procedurefont" class="heading-link"><i class="fas fa-link"></i></a>Pruning Procedure</h3>
      
<p><font face="Adobe Caslon Pro">在每一轮裁剪中，我们从每个卷积层和全连接层中删除固定百分比的可被裁剪的权重。同一层中的权重按其绝对大小排序，并选择最低的50％或75％予以裁剪，类似于[7]。为求简便，我们使用 one-shot pruning approach，尽管 incremental pruning 可以实现更好的性能[8]。</font></p>
<p><font face="Adobe Caslon Pro">我们发现没有必要学习类似于EWC [14]的 task-specific biases，于是选择在第一次裁剪和重新训练网络后保持所有层的 biases 固定。同样，在使用了 batch normalization 的网络中，在第一轮裁剪和重新训练之后，我们不会更新参数（gain，bias）或 running averages（mean，variance）。这种选择有助于减少额外的 per-task 的开销。</font></p>
<p><font face="Adobe Caslon Pro">添加多个任务的唯一开销是存储一个 sparsity mask，这个 sparsity mask 指示对某个任务有效的参数。通过这一迭代的训练过程，具体地，对于 Task <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07153em;">K</span></span></span></span> 而言，我们得到了一个filter，该 filter 是针对该特定任务学习的权重与针对先前 Task <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>1</mn><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><mi>K</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">1,...,K-1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.07153em;">K</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span> 所学习的权重的叠加。如果一个参数首先由 Task <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07153em;">K</span></span></span></span> 使用，它也将被之后的所有任务 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>K</mi><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><mi>N</mi></mrow><annotation encoding="application/x-tex">K,...,N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.07153em;">K</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span></span></span></span> 使用，其中 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span></span></span></span> 是任务总数。因此，我们最多需要 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mo><mi>log</mi><mo>⁡</mo></mo><mn>2</mn></msub><mo stretchy="false">(</mo><mi>N</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\log_2(N)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop"><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.20696799999999996em;"><span style="top:-2.4558600000000004em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.24414em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="mclose">)</span></span></span></span>  bit 来对每个参数的 mask 进行编码，而不是每个任务每个参数1bit。 </font></p>
<p><font face="Adobe Caslon Pro">再解释一下上一段，就是说如果一共有 N 个任务，任务序列为：<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>1</mn><mo separator="true">,</mo><mn>2</mn><mo separator="true">,</mo><mn>3</mn><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><mi>N</mi><mo>−</mo><mn>2</mn><mo separator="true">,</mo><mi>N</mi><mo>−</mo><mn>1</mn><mo separator="true">,</mo><mi>N</mi></mrow><annotation encoding="application/x-tex">1, 2, 3 , ... , N-2, N-1, N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">2</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">3</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord">2</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span></span></span></span>。那么Task 1 对应的参数也会被 Task 2、Task 3、… Task N-1、Task N 使用 ，后面的任务都会使用前面任务对应的（固定的）参数，并在此基础上训练得到一些新的参数。所以后面任务的 mask 必是前面任务的超集。</font></p>

        <h3 id="font-faceadobe-caslon-proinferencefont">
          <a href="#font-faceadobe-caslon-proinferencefont" class="heading-link"><i class="fas fa-link"></i></a>Inference</h3>
      
<p><font face="Adobe Caslon Pro">在对选定的任务进行 inference 的时候，网络参数会被 mask，以使网络状态与训练过程中学习到的网络状态匹配，即，Figure 1 (b) 中的 filters 用于 Task I 的 inference，Figure 1 (d) 中的 filters 用于 Task II 的 inference，如此等等。不需要额外的计算，因此也就没有额外的运行时（run-time）开销。权重只需要以二进制的 on/off 的方式被mask掉，这可以用矩阵-矩阵乘法实现。</font></p>
<p><font face="Adobe Caslon Pro">注意，我们的基于网络裁剪的方法不能对所有任务同时进行 inference，因为 filters 的响应会根据网络的稀疏程度而变化，并且在经过诸如ReLU之类的非线性之后不再可分离（separable）。执行 filter-level 的裁剪（开启/关闭整个 filter 而不是单个参数）可以允许同时的 inference。 但是，我们在 Section 5.5 中说明了，此类方法目前在裁剪能力方面受到限制，在不显著降低性能的情况下无法容纳多个任务。</font></p>

        <h2 id="font-faceadobe-caslon-prodiscussionfont">
          <a href="#font-faceadobe-caslon-prodiscussionfont" class="heading-link"><i class="fas fa-link"></i></a>Discussion</h2>
      
<p><font face="Adobe Caslon Pro">这篇文章有两点值得注意：(1) 每次裁剪的比例是固定的，而不是自适应的；(2) 文章提到 parameter-level 的裁剪不能同时 inference，但是filter-level 的可以，只是效果不好。</font></p>
<p><font face="Adobe Caslon Pro"></font></p>
<center><font face="楷体" color="grey"> 人生如梦，一尊还酹江月。</font></center>
</div><footer class="post-footer"><div class="post-ending ending"><div class="ending__text">------ END ------</div></div><div class="post-copyright copyright"><div class="copyright-author"><span class="copyright-author__name">Author: </span><span class="copyright-author__value"><a href="https://hello-liuyang.com">liuyang-70d12d</a></span></div><div class="copyright-link"><span class="copyright-link__name">Link: </span><span class="copyright-link__value"><a href="https://hello-liuyang.com/2020/12/13/Paper-Note-PackNet-Adding-Multiple-Tasks-to-a-Single-Network-by-Iterative-Pruning/">https://hello-liuyang.com/2020/12/13/Paper-Note-PackNet-Adding-Multiple-Tasks-to-a-Single-Network-by-Iterative-Pruning/</a></span></div><div class="copyright-notice"><span class="copyright-notice__name">Copyright: </span><span class="copyright-notice__value">All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en" rel="external nofollow" target="_blank">BY-NC-SA</a> unless stating additionally</span></div></div><div class="post-tags"><span class="post-tags-item"><span class="post-tags-item__icon"><i class="fas fa-tag"></i></span><a class="post-tags-item__link" href="https://hello-liuyang.com/tags/Continual-Learning/">Continual Learning</a></span></div><nav class="post-paginator paginator"><div class="paginator-prev"><a class="paginator-prev__link" href="/2020/12/14/%E5%80%BC%E5%BE%97follow%E7%9A%84%E4%B8%AA%E4%BA%BA%E4%B8%BB%E9%A1%B5-%E5%8D%9A%E5%AE%A2/"><span class="paginator-prev__icon"><i class="fas fa-angle-left"></i></span><span class="paginator-prev__text">值得follow的个人主页&amp;博客</span></a></div><div class="paginator-next"><a class="paginator-next__link" href="/2020/12/11/Paper-Note-Federated-Continual-Learning-with-Weighted-Inter-client-Transfer/"><span class="paginator-prev__text">Paper Note: Federated Continual Learning with Weighted Inter-client Transfer</span><span class="paginator-next__icon"><i class="fas fa-angle-right"></i></span></a></div></nav></footer></div></div></div><div class="sidebar-wrap" id="sidebar-wrap"><aside class="sidebar" id="sidebar"><div class="sidebar-nav"><span class="sidebar-nav-toc current">Catalog</span><span class="sidebar-nav-ov">Overview</span></div><section class="sidebar-toc"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#font-faceadobe-caslon-promain-ideafont"><span class="toc-number">1.</span> <span class="toc-text">
          Main Idea</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#font-faceadobe-caslon-prorelated-workfont"><span class="toc-number">2.</span> <span class="toc-text">
          Related Work</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#font-faceadobe-caslon-promethodfont"><span class="toc-number">3.</span> <span class="toc-text">
          Method</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#font-faceadobe-caslon-protrainingfont"><span class="toc-number">3.1.</span> <span class="toc-text">
          Training</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#font-faceadobe-caslon-propruning-procedurefont"><span class="toc-number">3.2.</span> <span class="toc-text">
          Pruning Procedure</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#font-faceadobe-caslon-proinferencefont"><span class="toc-number">3.3.</span> <span class="toc-text">
          Inference</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#font-faceadobe-caslon-prodiscussionfont"><span class="toc-number">4.</span> <span class="toc-text">
          Discussion</span></a></li></ol></section><!-- ov = overview--><section class="sidebar-ov hide"><div class="sidebar-ov-author"><div class="sidebar-ov-author__avatar"><img class="sidebar-ov-author__avatar_img" src="/assets/avatar/avatar.png" alt="avatar"></div></div><div class="sidebar-ov-social"><a class="sidebar-ov-social-item" href="mailto:ly_liuyang19@qq.com" target="_blank" rel="noopener" data-popover="social.mail" data-popover-pos="up"><span class="sidebar-ov-social-item__icon">Email</span></a></div><div class="sidebar-ov-state"><a class="sidebar-ov-state-item sidebar-ov-state-item--posts" href="/archives/"><div class="sidebar-ov-state-item__count">44</div><div class="sidebar-ov-state-item__name">Archives</div></a><a class="sidebar-ov-state-item sidebar-ov-state-item--tags" href="/tags/"><div class="sidebar-ov-state-item__count">18</div><div class="sidebar-ov-state-item__name">Tags</div></a></div><div class="sidebar-ov-cc"><a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en" target="_blank" rel="noopener" data-popover="Creative Commons" data-popover-pos="up"><img src="/images/cc-by-nc-sa.svg"></a></div></section><div class="sidebar-reading"><div class="sidebar-reading-info"><span class="sidebar-reading-info__text">You have read </span><span class="sidebar-reading-info__num">0</span><span class="sidebar-reading-info__perc">%</span></div><div class="sidebar-reading-line"></div></div></aside></div><div class="clearfix"></div></div></main><footer class="footer" id="footer"><div class="footer-inner"><div><span>Copyright © 2021</span><span class="footer__icon"><i class="fas fa-heart"></i></span><span>liuyang-70d12d</span></div><div><span>Powered by <a href="http://hexo.io/" title="Hexo" target="_blank" rel="noopener">Hexo</a></span><span> v5.2.0</span><span class="footer__devider">|</span><span>Theme - <a href="https://github.com/liuyib/hexo-theme-stun/" title="Stun" target="_blank" rel="noopener">Stun</a></span><span> v2.3.0</span></div><div class="busuanzi"><span class="busuanzi-siteuv"><span class="busuanzi-siteuv__icon"><i class="fas fa-user"></i></span><span class="busuanzi-siteuv__info">Visitors</span><span class="busuanzi-siteuv__value" id="busuanzi_value_site_uv"></span></span><span class="busuanzi-sitepv"><span class="busuanzi-siteuv__icon"><i class="fas fa-eye"></i></span><span class="busuanzi-siteuv__info">Views</span><span class="busuanzi-siteuv__value" id="busuanzi_value_site_pv"></span></span></div><div><span id="timeDate">载入天数...</span><span id="times">载入时分秒...</span><script>var now = new Date();
function createtime() {
var grt= new Date("11/09/2020 00:00:00");
now.setTime(now.getTime()+250);
days = (now - grt ) / 1000 / 60 / 60 / 24; dnum = Math.floor(days);
hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum); hnum = Math.floor(hours);
if(String(hnum).length ==1 ){hnum = "0" + hnum;} minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum);
mnum = Math.floor(minutes); if(String(mnum).length ==1 ){mnum = "0" + mnum;}
seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum);
snum = Math.round(seconds); if(String(snum).length ==1 ){snum = "0" + snum;}
document.getElementById("timeDate").innerHTML = "我已来到这个世界 "+dnum+" 天 ";
document.getElementById("times").innerHTML = hnum + " 小时 " + mnum + " 分 " + snum + " 秒";
}
setInterval("createtime()",250);</script></div></div></footer><div class="loading-bar" id="loading-bar"><div class="loading-bar__progress"></div></div><div class="back2top" id="back2top"><span class="back2top__icon"><i class="fas fa-rocket"></i></span></div></div><script src="https://cdn.jsdelivr.net/npm/jquery@v3.4.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@1.5.2/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@1.5.2/velocity.ui.min.js"></script><link href="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.css" rel="stylesheet" type="text/css"><link href="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/contrib/copy-tex.css" rel="stylesheet" type="text/css"><script src="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/contrib/copy-tex.min.js"></script><script src="https://cdn.jsdelivr.net/gh/sukkaw/busuanzi@latest/bsz.pure.mini.js" async></script><script src="/js/utils.js?v=2.3.0"></script><script src="/js/stun-boot.js?v=2.3.0"></script><script src="/js/scroll.js?v=2.3.0"></script><script src="/js/header.js?v=2.3.0"></script><script src="/js/sidebar.js?v=2.3.0"></script></body></html>